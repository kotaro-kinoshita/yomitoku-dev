{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#_1","title":"\ud83c\udf1f \u6982\u8981","text":"<p>YomiToku \u306f\u65e5\u672c\u8a9e\u306b\u7279\u5316\u3057\u305f AI \u6587\u7ae0\u753b\u50cf\u89e3\u6790\u30a8\u30f3\u30b8\u30f3(Document AI)\u3067\u3059\u3002\u753b\u50cf\u5185\u306e\u6587\u5b57\u306e\u5168\u6587 OCR \u304a\u3088\u3073\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u6a5f\u80fd\u3092\u6709\u3057\u3066\u304a\u308a\u3001\u753b\u50cf\u5185\u306e\u6587\u5b57\u60c5\u5831\u3084\u56f3\u8868\u3092\u8a8d\u8b58\u3001\u62bd\u51fa\u3001\u5909\u63db\u3057\u307e\u3059\u3002</p> <ul> <li>\ud83e\udd16 \u65e5\u672c\u8a9e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u5b66\u7fd2\u3057\u305f 4 \u7a2e\u985e(\u6587\u5b57\u4f4d\u7f6e\u306e\u691c\u77e5\u3001\u6587\u5b57\u5217\u8a8d\u8b58\u3001\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3001\u8868\u306e\u69cb\u9020\u8a8d\u8b58)\u306e AI \u30e2\u30c7\u30eb\u3092\u642d\u8f09\u3057\u3066\u3044\u307e\u3059\u30024 \u7a2e\u985e\u306e\u30e2\u30c7\u30eb\u306f\u3059\u3079\u3066\u72ec\u81ea\u306b\u5b66\u7fd2\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3067\u65e5\u672c\u8a9e\u6587\u66f8\u306b\u5bfe\u3057\u3066\u3001\u9ad8\u7cbe\u5ea6\u306b\u63a8\u8ad6\u53ef\u80fd\u3067\u3059\u3002</li> <li>\ud83c\uddef\ud83c\uddf5 \u5404\u30e2\u30c7\u30eb\u306f\u65e5\u672c\u8a9e\u306e\u6587\u66f8\u753b\u50cf\u306b\u7279\u5316\u3057\u3066\u5b66\u7fd2\u3055\u308c\u3066\u304a\u308a\u30017000 \u6587\u5b57\u3092\u8d85\u3048\u308b\u65e5\u672c\u8a9e\u6587\u5b57\u306e\u8a8d\u8b58\u3092\u30b5\u30fc\u30dd\u30fc\u30c8\u3001\u7e26\u66f8\u304d\u306a\u3069\u65e5\u672c\u8a9e\u7279\u6709\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u69cb\u9020\u306e\u6587\u66f8\u753b\u50cf\u306e\u89e3\u6790\u3082\u53ef\u80fd\u3067\u3059\u3002\uff08\u65e5\u672c\u8a9e\u4ee5\u5916\u306b\u3082\u82f1\u8a9e\u306e\u6587\u66f8\u306b\u5bfe\u3057\u3066\u3082\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\uff09\u3002</li> <li>\ud83d\udcc8 \u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3001\u8868\u306e\u69cb\u9020\u89e3\u6790, \u8aad\u307f\u9806\u63a8\u5b9a\u6a5f\u80fd\u306b\u3088\u308a\u3001\u6587\u66f8\u753b\u50cf\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u306e\u610f\u5473\u7684\u69cb\u9020\u3092\u58ca\u3055\u305a\u306b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002</li> <li>\ud83d\udcc4 \u591a\u69d8\u306a\u51fa\u529b\u5f62\u5f0f\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002html \u3084\u30de\u30fc\u30af\u30c0\u30a6\u30f3\u3001json\u3001csv \u306e\u3044\u305a\u308c\u304b\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u5909\u63db\u53ef\u80fd\u3067\u3059\u3002\u307e\u305f\u3001\u6587\u66f8\u5185\u306b\u542b\u307e\u308c\u308b\u56f3\u8868\u3001\u753b\u50cf\u306e\u62bd\u51fa\u306e\u51fa\u529b\u3082\u53ef\u80fd\u3067\u3059\u3002</li> <li>\u26a1 GPU\u74b0\u5883\u3067\u9ad8\u901f\u306b\u52d5\u4f5c\u3057\u3001\u52b9\u7387\u7684\u306b\u6587\u66f8\u306e\u6587\u5b57\u8d77\u3053\u3057\u89e3\u6790\u304c\u53ef\u80fd\u3067\u3059\u3002\u307e\u305f\u3001VRAM\u30828GB\u4ee5\u5185\u3067\u52d5\u4f5c\u3057\u3001\u30cf\u30a4\u30a8\u30f3\u30c9\u306aGPU\u3092\u7528\u610f\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002</li> </ul>"},{"location":"#faq","title":"\ud83d\ude4b FAQ","text":""},{"location":"#q","title":"Q. \u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u52d5\u4f5c\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f","text":"<p>A. \u53ef\u80fd\u3067\u3059\u3002Yomitoku \u306f\u521d\u56de\u5b9f\u884c\u6642\u306b HuggingFaceHub \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3001\u81ea\u52d5\u3067\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3092\u884c\u3044\u307e\u3059\u304c\u3001\u3053\u306e\u969b\u306b\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3057\u307e\u3059\u3002\u3057\u304b\u3057\u3001\u4e8b\u524d\u306b\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3067\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u3078\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u3082\u52d5\u4f5c\u53ef\u80fd\u3067\u3059\u3002\u8a73\u3057\u304f\u306fUsase\u306e\u300c\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u5229\u7528\u300d\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"#q_1","title":"Q. \u5546\u7528\u5229\u7528\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f","text":"<p>A. \u672c\u30d1\u30c3\u30b1\u30fc\u30b8\u306f CC BY-NC 4.0 \u306b\u5f93\u3044\u307e\u3059\u3002\u500b\u4eba\u306e\u5229\u7528\u3084\u7814\u7a76\u5229\u7528\u306b\u95a2\u3057\u3066\u306f\u7121\u511f\u3067\u3054\u5229\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002\u5546\u7528\u5229\u7528\u306b\u95a2\u3057\u3066\u306f\u3001\u5225\u9014\u3001\u6709\u511f\u306e\u5546\u7528\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u767a\u884c\u3057\u307e\u3059\u306e\u3067\u3001\u958b\u767a\u8005\u307e\u3067\u554f\u3044\u5408\u308f\u305b\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"#q_2","title":"Q. \u624b\u66f8\u304d\u6587\u5b57\u306f\u8a8d\u8b58\u3067\u304d\u307e\u3059\u304b\uff1f","text":"<p>A. \u6d3b\u5b57\u306e\u307f\u306e\u8b58\u5225\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u3059\u3002\u624b\u66f8\u304d\u6587\u5b57\u306b\u95a2\u3057\u3066\u306f\u3001\u8aad\u307f\u53d6\u308c\u308b\u5834\u5408\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u516c\u5f0f\u306b\u306f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u305b\u3093\u3002</p>"},{"location":"installation/","title":"Installation","text":"<p>\u672c\u30d1\u30c3\u30b1\u30fc\u30b8\u306f Python3.10+, Pytorch \u304c\u5b9f\u884c\u306b\u5fc5\u8981\u3067\u3059\u3002Pytorch \u306f\u3054\u81ea\u8eab\u306e\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\u3067\u3059\u3002\u8a08\u7b97\u6a5f\u306f GPU(&gt; VRAM 8G)\u3092\u63a8\u5968\u3057\u3066\u3044\u307e\u3059\u3002CPU \u3067\u3082\u52d5\u4f5c\u3057\u307e\u3059\u304c\u3001\u73fe\u5728\u3001CPU \u5411\u3051\u306b\u51e6\u7406\u304c\u6700\u9069\u5316\u3055\u308c\u3066\u304a\u3089\u305a\u3001\u5b9f\u884c\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u306e\u3067\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"installation/#pypi","title":"PYPI \u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>pip install yomitoku\n</code></pre>"},{"location":"installation/#uv","title":"uv \u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>\u672c\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u30d1\u30c3\u30b1\u30fc\u30b8\u7ba1\u7406\u30c4\u30fc\u30eb\u306b uv \u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002uv \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5f8c\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u30af\u30ed\u30fc\u30f3\u3057\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044</p> <pre><code>uv sync\n</code></pre> <p>uv\u3092\u5229\u7528\u3059\u308b\u5834\u5408\u3001<code>pyproject.toml</code>\u306e\u4ee5\u4e0b\u306e\u90e8\u5206\u3092\u3054\u81ea\u8eab\u306ecuda\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5408\u308f\u305b\u3066\u4fee\u6b63\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fCUDA12.4\u306b\u5bfe\u5fdc\u3057\u305fpytorch\u304c\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u307e\u3059\u3002</p> <pre><code>[[tool.uv.index]]\nname = \"pytorch-cuda124\"\nurl = \"https://download.pytorch.org/whl/cu124\"\nexplicit = true\n</code></pre>"},{"location":"installation/#docker","title":"Docker \u74b0\u5883\u3067\u306e\u5b9f\u884c","text":"<p>\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u76f4\u4e0b\u306b dockerfile \u3092\u914d\u7f6e\u3057\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u305d\u3061\u3089\u3082\u6d3b\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p> <pre><code>docker build -t yomitoku .\n</code></pre> GPUCPU <pre><code>docker run -it --gpus all -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre> <pre><code>docker run -it -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#cli","title":"CLI \u304b\u3089\u306e\u5229\u7528","text":"<p>\u521d\u56de\u306e\u5b9f\u884c\u6642\u306e\u307f, HuggingFaseHub \u304b\u3089\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} -f md -o results -v\n</code></pre> <ul> <li><code>${path_data}</code> \u89e3\u6790\u5bfe\u8c61\u306e\u753b\u50cf\u304c\u542b\u307e\u308c\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304b\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u76f4\u63a5\u3057\u3066\u6307\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u304b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u5bfe\u8c61\u3068\u3057\u305f\u5834\u5408\u306f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306e\u753b\u50cf\u3082\u542b\u3081\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u5165\u529b\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u308b\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u306f jpeg, png, bmp, tiff, pdf \u3067\u3059\u3002</li> <li><code>-f</code> \u51fa\u529b\u5f62\u5f0f\u306e\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(json, csv, html, md \u3092\u30b5\u30dd\u30fc\u30c8)</li> <li><code>-l</code> \u6307\u5b9a\u3059\u308b\u3068\u8efd\u91cf\u30e2\u30c7\u30eb\u3067\u63a8\u8ad6\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002CPU\u3067\u3082\u9ad8\u901f\u306b\u63a8\u8ad6\u53ef\u80fd\u3067\u3059\u3002</li> <li><code>-o</code> \u51fa\u529b\u5148\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u65b0\u898f\u3067\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002</li> <li><code>-v</code> \u3092\u6307\u5b9a\u3059\u308b\u3068\u89e3\u6790\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u753b\u50cf\u3092\u51fa\u529b\u3057\u307e\u3059\u3002</li> <li><code>-d</code> \u30e2\u30c7\u30eb\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002gpu \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f cpu \u3067\u63a8\u8ad6\u304c\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002(\u30c7\u30d5\u30a9\u30eb\u30c8: cuda)</li> </ul>"},{"location":"usage/#note","title":"Note:","text":"<ul> <li>CPU \u3092\u7528\u3044\u3066\u306e\u63a8\u8ad6\u5411\u3051\u306b\u6700\u9069\u5316\u3055\u308c\u3066\u304a\u3089\u305a\u3001\u51e6\u7406\u6642\u9593\u304c\u9577\u304f\u306a\u308a\u307e\u3059\u306e\u3067\u3001GPU \u3092\u7528\u3044\u3066\u3067\u3082\u5b9f\u884c\u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li>\u6d3b\u5b57\u306e\u307f\u306e\u8b58\u5225\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u3059\u3002\u624b\u66f8\u304d\u6587\u5b57\u306b\u95a2\u3057\u3066\u306f\u3001\u8aad\u307f\u53d6\u308c\u308b\u5834\u5408\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u516c\u5f0f\u306b\u306f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u305b\u3093\u3002</li> <li>OCR \u306f\u6587\u66f8 OCR \u3068\u60c5\u666f OCR(\u770b\u677f\u306a\u3069\u7d19\u4ee5\u5916\u306b\u30d7\u30ea\u30f3\u30c8\u3055\u308c\u305f\u6587\u5b57)\u306b\u5927\u5225\u3055\u308c\u307e\u3059\u304c\u3001Yomitoku \u306f\u6587\u66f8 OCR \u5411\u3051\u306b\u6700\u9069\u5316\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> <li>AI-OCR \u306e\u8b58\u5225\u7cbe\u5ea6\u3092\u9ad8\u3081\u308b\u305f\u3081\u306b\u3001\u5165\u529b\u753b\u50cf\u306e\u89e3\u50cf\u5ea6\u304c\u91cd\u8981\u3067\u3059\u3002\u4f4e\u89e3\u50cf\u5ea6\u753b\u50cf\u3067\u306f\u8b58\u5225\u7cbe\u5ea6\u304c\u4f4e\u4e0b\u3057\u307e\u3059\u3002\u753b\u50cf\u306e\u77ed\u8fba\u3092 1000px \u4ee5\u4e0a\u306e\u753b\u50cf\u3067\u63a8\u8ad6\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"usage/#python","title":"Python \u306e\u30b3\u30fc\u30c9\u5185\u3067\u306e\u5229\u7528","text":""},{"location":"usage/#document-analyzer","title":"Document Analyzer \u306e\u5229\u7528","text":"<p>Document Analyzer \u306f OCR \u304a\u3088\u3073\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3092\u5b9f\u884c\u3057\u3001\u305d\u308c\u3089\u306e\u7d50\u679c\u3092\u7d71\u5408\u3057\u305f\u89e3\u6790\u7d50\u679c\u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u6bb5\u843d\u3001\u8868\u306e\u69cb\u9020\u89e3\u6790\u3001\u62bd\u51fa\u3001\u56f3\u8868\u306e\u691c\u77e5\u306a\u3069\u69d8\u3005\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306b\u3054\u5229\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p> <pre><code>import cv2\n\nfrom yomitoku import DocumentAnalyzer\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    analyzer = DocumentAnalyzer(configs=None, visualize=True, device=\"cuda\")\n    results, ocr_vis, layout_vis = analyzer(img)\n\n    # HTML\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_html(PATH_OUTPUT)\n\n    # \u53ef\u8996\u5316\u753b\u50cf\u3092\u4fdd\u5b58\n    cv2.imwrite(\"output_ocr.jpg\", ocr_vis)\n    cv2.imwrite(\"output_layout.jpg\", layout_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>DocumentAnalyzer</code> \u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f\u4ee5\u4e0b\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002</p> <ul> <li><code>to_json()</code>: JSON \u5f62\u5f0f(*.json)</li> <li><code>to_html()</code>: HTML \u5f62\u5f0f(*.html)</li> <li><code>to_csv()</code>: \u30ab\u30f3\u30de\u533a\u5207\u308a CSV \u5f62\u5f0f(*.csv)</li> <li><code>to_markdown()</code>: \u30de\u30fc\u30af\u30c0\u30a6\u30f3\u5f62\u5f0f(*.md)</li> </ul>"},{"location":"usage/#ai-ocr","title":"AI-OCR \u306e\u307f\u306e\u5229\u7528","text":"<p>AI-OCR \u3067\u306f\u3001\u30c6\u30ad\u30b9\u30c8\u691c\u77e5\u3068\u691c\u77e5\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u306b\u5bfe\u3057\u3066\u3001\u8a8d\u8b58\u51e6\u7406\u3092\u5b9f\u884c\u3057\u3001\u753b\u50cf\u5185\u306e\u6587\u5b57\u306e\u4f4d\u7f6e\u3068\u8aad\u307f\u53d6\u308a\u7d50\u679c\u3092\u8fd4\u5374\u3057\u307e\u3059\u3002</p> <pre><code>import cv2\n\nfrom yomitoku import OCR\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    ocr = OCR(configs=None, visualize=True, device=\"cuda\")\n    results, ocr_vis = ocr(img)\n\n    # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_json(PATH_OUTPUT)\n    cv2.imwrite(\"output_ocr.jpg\", ocr_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>OCR</code>\u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f JSON \u7cfb\u5f62\u5f0f(<code>to_json()</code>)\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"usage/#layout-analyzer","title":"Layout Analyzer \u306e\u307f\u306e\u5229\u7528","text":"<p>LayoutAnalyzer \u3067\u306f\u3001\u30c6\u30ad\u30b9\u30c8\u691c\u77e5\u3068\u691c\u77e5\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u306b\u5bfe\u3057\u3066\u3001\u6bb5\u843d\u3001\u56f3\u8868\u306e\u691c\u77e5\u304a\u3088\u3073\u8868\u306e\u69cb\u9020\u89e3\u6790\u51e6\u7406 AI \u3092\u5b9f\u884c\u3057\u3001\u6587\u66f8\u5185\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u69cb\u9020\u3092\u89e3\u6790\u3057\u307e\u3059\u3002</p> <pre><code>import cv2\n\nfrom yomitoku import LayoutAnalyzer\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    analyzer = LayoutAnalyzer(configs=None, visualize=True, device=\"cuda\")\n    results, layout_vis = analyzer(img)\n\n    # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_json(PATH_OUTPUT)\n    cv2.imwrite(\"output_layout.jpg\", layout_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>LayoutAnalyzer</code>\u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f JSON \u7cfb\u5f62\u5f0f(<code>to_json()</code>)\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"usage/#_1","title":"\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u8a73\u7d30\u8a2d\u5b9a","text":"<p>Config \u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u3001\u3088\u308a\u7d30\u304b\u3044\u632f\u308b\u821e\u3044\u3092\u8abf\u6574\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"usage/#config","title":"Config \u306e\u8a18\u8ff0\u65b9\u6cd5","text":"<p>config \u306f\u8f9e\u66f8\u5f62\u5f0f\u3067\u4e0e\u3048\u307e\u3059\u3002config \u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u30e2\u30b8\u30e5\u30fc\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u8a08\u7b97\u6a5f\u3067\u51e6\u7406\u3092\u5b9f\u884c\u3057\u305f\u308a\u3001\u8a73\u7d30\u306e\u30d1\u30e9\u30fc\u30e1\u30bf\u306e\u8a2d\u5b9a\u304c\u53ef\u80fd\u3067\u3059\u3002\u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306a config \u3092\u4e0e\u3048\u308b\u3068\u3001OCR \u51e6\u7406\u306f GPU \u3067\u5b9f\u884c\u3057\u3001\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u6a5f\u80fd\u306f CPU \u3067\u5b9f\u884c\u3057\u307e\u3059\u3002</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"device\": \"cuda\",\n            },\n            \"text_recognizer\": {\n                \"device\": \"cuda\",\n            },\n        },\n        \"layout_analyzer\": {\n            \"layout_parser\": {\n                \"device\": \"cpu\",\n            },\n            \"table_structure_recognizer\": {\n                \"device\": \"cpu\",\n            },\n        },\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"usage/#yaml","title":"yaml \u30d5\u30a1\u30a4\u30eb\u3067\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5b9a\u7fa9","text":"<p>Config \u306b yaml \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u3001\u63a8\u8ad6\u6642\u306e\u7d30\u90e8\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8abf\u6574\u304c\u53ef\u80fd\u3067\u3059\u3002yaml \u30d5\u30a1\u30a4\u30eb\u306e\u4f8b\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u5185\u306e<code>configs</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306b\u3042\u308a\u307e\u3059\u3002\u30e2\u30c7\u30eb\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u5909\u66f4\u3067\u304d\u307e\u305b\u3093\u304c\u3001\u5f8c\u51e6\u7406\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3084\u5165\u529b\u753b\u50cf\u306e\u30b5\u30a4\u30ba\u306a\u3069\u306f\u4e00\u90e8\u5909\u66f4\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u305f\u3068\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b<code>Text Detector</code>\u306e\u5f8c\u51e6\u7406\u306e\u95be\u5024\u3092 yaml \u3092\u5b9a\u7fa9\u3057\u3001config \u306b\u30d1\u30b9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002config \u30d5\u30a1\u30a4\u30eb\u306f\u3059\u3079\u3066\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a18\u8f09\u3059\u308b\u5fc5\u8981\u306f\u306a\u304f\u3001\u5909\u66f4\u304c\u5fc5\u8981\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u306e\u8a18\u8f09\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <p><code>text_detector.yaml</code>\u306e\u8a18\u8ff0</p> <pre><code>post_process:\n  thresh: 0.1\n  unclip_ratio: 2.5\n</code></pre> <p>yaml \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092 config \u306b\u683c\u7d0d\u3059\u308b</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    # path_cfg\u306b\u8a2d\u5b9a\u3057\u305fymal\u306e\u30d1\u30b9\u3092\u8a18\u8ff0\u3059\u308b\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"path_cfg\": \"text_detector.yaml\"\n            }\n        }\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"usage/#_2","title":"\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u5229\u7528","text":"<p>Yomitoku \u306f\u521d\u56de\u306e\u5b9f\u884c\u6642\u306b HuggingFaceHub \u304b\u3089\u30e2\u30c7\u30eb\u3092\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\u305d\u306e\u969b\u306b\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u74b0\u5883\u304c\u5fc5\u8981\u3067\u3059\u304c\u3001\u4e8b\u524d\u306b\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3067\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u3082\u5b9f\u884c\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <ol> <li> <p>Git Large File Storage\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb</p> </li> <li> <p>\u4e8b\u524d\u306b\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u308b\u74b0\u5883\u3067\u30e2\u30c7\u30eb\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\u30af\u30ed\u30fc\u30f3\u3057\u305f\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u3054\u81ea\u8eab\u306e\u30c4\u30fc\u30eb\u3067\u52d5\u4f5c\u74b0\u5883\u306b\u30b3\u30d4\u30fc\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> </li> </ol> <p>\u4ee5\u4e0b\u306f huggingfacehub \u304b\u3089\u30e2\u30c7\u30eb\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u30b3\u30de\u30f3\u30c9</p> <pre><code>git clone https://huggingface.co/KotaroKinoshita/yomitoku-table-structure-recognizer-rtdtrv2-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-layout-parser-rtdtrv2-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-text-detector-dbnet-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-text-recognizer-parseq-open-beta\n</code></pre> <ol> <li>yomitoku \u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u76f4\u4e0b\u306b\u30e2\u30c7\u30eb\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u914d\u7f6e\u3057\u3001yaml \u30d5\u30a1\u30a4\u30eb\u306e<code>hf_hub_repo</code>\u3067\u30ed\u30fc\u30ab\u30eb\u306e\u30e2\u30c7\u30eb\u30ec\u30dd\u30b8\u30c8\u30ea\u3092\u53c2\u7167\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306f <code>text_detector.yaml</code> \u306e\u4f8b\u3067\u3059\u3002\u540c\u69d8\u306b\u4ed6\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5bfe\u3057\u3066\u3082 yaml \u30d5\u30a1\u30a4\u30eb\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002</li> </ol> <pre><code>hf_hub_repo: yomitoku-text-detector-dbnet-open-beta\n</code></pre> <ol> <li>yaml \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092 config \u306b\u683c\u7d0d\u3059\u308b</li> </ol> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    # path_cfg\u306b\u8a2d\u5b9a\u3057\u305fymal\u306e\u30d1\u30b9\u3092\u8a18\u8ff0\u3059\u308b\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"path_cfg\": \"text_detector.yaml\"\n            }\n        }\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"en/#introduction","title":"\ud83c\udf1f Introduction","text":"<p>YomiToku is a Document AI engine specialized in Japanese document image analysis. It provides full OCR (optical character recognition) and layout analysis capabilities, enabling the recognition, extraction, and conversion of text and diagrams from images.</p> <ul> <li>\ud83e\udd16 Equipped with four AI models trained on Japanese datasets: text detection, text recognition, layout analysis, and table structure recognition. All models are independently trained and optimized for Japanese documents, delivering high-precision inference.</li> <li>\ud83c\uddef\ud83c\uddf5 Each model is specifically trained for Japanese document images, supporting the recognition of over 7,000 Japanese characters, including vertical text and other layout structures unique to Japanese documents. (It also supports English documents.)</li> <li>\ud83d\udcc8 By leveraging layout analysis, table structure parsing, and reading order estimation, it extracts information while preserving the semantic structure of the document layout.</li> <li>\ud83d\udcc4 Supports a variety of output formats, including HTML, Markdown, JSON, and CSV. It also allows for the extraction of diagrams and images contained within the documents.</li> <li>\u26a1 Operates efficiently in GPU environments, enabling fast document transcription and analysis. It requires less than 8GB of VRAM, eliminating the need for high-end GPUs.\u3002</li> </ul>"},{"location":"en/#q-is-it-possible-to-use-yomitoku-in-an-environment-without-internet-access","title":"Q. Is it possible to use YomiToku in an environment without internet access?","text":"<p>A. Yes, it is possible. YomiToku connects to Hugging Face Hub to automatically download model files during the first execution, requiring internet access at that time. However, you can manually download the files in advance, allowing YomiToku to operate in an offline environment. For details, please refer to Usage under the section \"Using YomiToku in an Offline Environment.\"</p>"},{"location":"en/#q-is-commercial-use-allowed","title":"Q. Is commercial use allowed?","text":"<p>A. This package is licensed under CC BY-NC 4.0. It is available for free for personal and research purposes. For commercial use, a paid commercial license is required. Please contact the developers for further details.</p>"},{"location":"en/#q-can-handwritten-text-be-recognized","title":"Q. Can handwritten text be recognized?","text":"<p>A. Only printed text recognition is supported. While handwritten text may occasionally be recognized, it is not officially supported.</p>"},{"location":"en/installation/","title":"Installation","text":"<p>This package requires Python 3.10 or later and PyTorch 2.5 or later for execution. PyTorch must be installed according to your CUDA version. A GPU with more than 8GB of VRAM is recommended. While it can run on a CPU, please note that the processing is not currently optimized for CPUs, which may result in longer execution times.</p>"},{"location":"en/installation/#from-pypi","title":"from PYPI","text":"<pre><code>pip install yomitoku\n</code></pre>"},{"location":"en/installation/#using-uv","title":"using uv","text":"<p>This repository uses the package management tool uv. After installing uv, clone the repository and execute the following commands:</p> <pre><code>uv sync\n</code></pre> <p>When using uv, you need to modify the following part of the pyproject.toml file to match your CUDA version. By default, PyTorch compatible with CUDA 12.4 will be downloaded.</p> <pre><code>[[tool.uv.index]]\nname = \"pytorch-cuda124\"\nurl = \"https://download.pytorch.org/whl/cu124\"\nexplicit = true\n</code></pre>"},{"location":"en/installation/#using-docker","title":"using docker","text":"<p>A Dockerfile is provided in the root of the repository, which you are welcome to use.</p> <pre><code>docker build -t yomitoku .\n</code></pre> GPUCPU <pre><code>docker run -it --gpus all -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre> <pre><code>docker run -it -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre>"},{"location":"en/usage/#cli","title":"CLI","text":"<p>The model weight files are downloaded from Hugging Face Hub only during the first execution.</p> <pre><code>yomitoku ${path_data} -f md -o results -v\n</code></pre> <ul> <li><code>${path_data}</code>: Specify the path to a directory containing images to be analyzed or directly provide the path to an image file. If a directory is specified, images in its subdirectories will also be processed.</li> <li><code>-f</code>, <code>--format</code>: Specify the output file format. Supported formats are json, csv, html, and md.</li> <li><code>-o</code>, <code>--outdir</code>: Specify the name of the output directory. If it does not exist, it will be created.</li> <li><code>-v</code>, <code>--vis</code>: If specified, outputs visualized images of the analysis results.</li> <li><code>-l</code>, <code>--lite</code>: inference is performed using a lightweight model. This enables fast inference even on a CPU.</li> <li><code>-d</code>, <code>--device</code>: Specify the device for running the model. If a GPU is unavailable, inference will be executed on the CPU. (Default: cuda)</li> <li><code>--ignore_line_break</code>: Ignores line breaks in the image and concatenates sentences within a paragraph. (Default: respects line breaks as they appear in the image.)</li> <li><code>--figure_letter</code>: Exports characters contained within detected figures and tables to the output file.</li> <li><code>--figure</code>: Exports detected figures and images to the output file (supported only for html and markdown).</li> </ul> <p>NOTE - It is recommended to run on a GPU. The system is not optimized for inference on CPUs, which may result in significantly longer processing times. - Only printed text recognition is supported. While it may occasionally read handwritten text, official support is not provided. - YomiToku is optimized for document OCR and is not designed for scene OCR (e.g., text printed on non-paper surfaces like signs). - The resolution of input images is critical for improving the accuracy of AI-OCR recognition. Low-resolution images may lead to reduced recognition accuracy. It is recommended to use images with a minimum short side resolution of 720px for inference.</p>"},{"location":"en/usage/#calling-from-within-python-code","title":"Calling from within Python code","text":""},{"location":"en/usage/#document-analyzer","title":"Document Analyzer \u306e\u5229\u7528","text":"<p>The Document Analyzer performs OCR and layout analysis, integrating these results into a comprehensive analysis output. It can be used for various use cases, including paragraph and table structure analysis, extraction, and figure/table detection.</p> <pre><code>import cv2\n\nfrom yomitoku import DocumentAnalyzer\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    analyzer = DocumentAnalyzer(configs=None, visualize=True, device=\"cuda\")\n    results, ocr_vis, layout_vis = analyzer(img)\n\n    # HTML\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_html(PATH_OUTPUT)\n\n    # \u53ef\u8996\u5316\u753b\u50cf\u3092\u4fdd\u5b58\n    cv2.imwrite(\"output_ocr.jpg\", ocr_vis)\n    cv2.imwrite(\"output_layout.jpg\", layout_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is \"cuda\". If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of DocumentAnalyzer can be exported in the following formats:</p> <p><code>to_json()</code>: JSON format (.json) <code>to_html()</code>: HTML format (.html) <code>to_csv()</code>: Comma-separated CSV format (.csv) <code>to_markdown()</code>: Markdown format (.md)</p>"},{"location":"en/usage/#using-ai-ocr-only","title":"Using AI-OCR Only","text":"<p>AI-OCR performs text detection and recognition on the detected text, returning the positions of the text within the image along with the recognition results.</p> <pre><code>import cv2\n\nfrom yomitoku import OCR\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    ocr = OCR(configs=None, visualize=True, device=\"cuda\")\n    results, ocr_vis = ocr(img)\n\n    # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_json(PATH_OUTPUT)\n    cv2.imwrite(\"output_ocr.jpg\", ocr_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is \"cuda\". If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of OCR processing support export in JSON format (<code>to_json()</code>) only.</p>"},{"location":"en/usage/#using-layout-analyzer-only","title":"Using Layout Analyzer only","text":"<p>The <code>LayoutAnalyzer</code> performs text detection, followed by AI-based paragraph, figure/table detection, and table structure analysis. It analyzes the layout structure within the document.</p> <pre><code>import cv2\n\nfrom yomitoku import LayoutAnalyzer\nfrom yomitoku.data.functions import load_image\n\nif __name__ == \"__main__\":\n    img = load_image(PATH_IMAGE)\n    analyzer = LayoutAnalyzer(configs=None, visualize=True, device=\"cuda\")\n    results, layout_vis = analyzer(img)\n\n    # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n    results.to_json(PATH_OUTPUT)\n    cv2.imwrite(\"output_layout.jpg\", layout_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is \"cuda\". If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of LayoutAnalyzer processing support export only in JSON format (to_json()).</p>"},{"location":"en/usage/#detailed-configuration-of-the-pipeline","title":"Detailed Configuration of the Pipeline","text":"<p>By providing a config, you can adjust the behavior in greater detail.</p>"},{"location":"en/usage/#how-to-write-a-config","title":"How to Write a Config","text":"<p>The config is provided in dictionary format. By using a config, you can execute processing on different devices for each module and set detailed parameters. For example, the following config allows the OCR processing to run on a GPU, while the layout analysis is performed on a CPU:</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"device\": \"cuda\",\n            },\n            \"text_recognizer\": {\n                \"device\": \"cuda\",\n            },\n        },\n        \"layout_analyzer\": {\n            \"layout_parser\": {\n                \"device\": \"cpu\",\n            },\n            \"table_structure_recognizer\": {\n                \"device\": \"cpu\",\n            },\n        },\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"en/usage/#defining-parameters-in-an-yaml-file","title":"Defining Parameters in an YAML File","text":"<p>By providing the path to a YAML file in the config, you can adjust detailed parameters for inference. Examples of YAML files can be found in the <code>configs</code> directory within the repository. While the model's network parameters cannot be modified, certain aspects like post-processing parameters and input image size can be adjusted.</p> <p>For instance, you can define post-processing thresholds for the Text Detector in a YAML file and set its path in the config. The config file does not need to include all parameters; you only need to specify the parameters that require changes.</p> <pre><code>post_process:\n  thresh: 0.1\n  unclip_ratio: 2.5\n</code></pre> <p>Storing the Path to a YAML File in the Config</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    # path_cfg\u306b\u8a2d\u5b9a\u3057\u305fymal\u306e\u30d1\u30b9\u3092\u8a18\u8ff0\u3059\u308b\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"path_cfg\": \"text_detector.yaml\"\n            }\n        }\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"en/usage/#using-in-an-offline-environment","title":"Using in an Offline Environment","text":"<p>Yomitoku automatically downloads models from Hugging Face Hub during the first execution, requiring an internet connection at that time. However, by manually downloading the models in advance, it can be executed in an offline environment.</p> <ol> <li>Install Git Large File Storage</li> <li>In an environment with internet access, download the model repository. Copy the cloned repository to your target environment using your preferred tools.</li> </ol> <p>The following is the command to download the model repository from Hugging Face Hub.</p> <pre><code>git clone https://huggingface.co/KotaroKinoshita/yomitoku-table-structure-recognizer-rtdtrv2-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-layout-parser-rtdtrv2-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-text-detector-dbnet-open-beta\n\ngit clone https://huggingface.co/KotaroKinoshita/yomitoku-text-recognizer-parseq-open-beta\n</code></pre> <ol> <li>Place the model repository directly under the root directory of the Yomitoku repository and reference the local model repository in the <code>hf_hub_repo</code> field of the YAML file. Below is an example of <code>text_detector.yaml</code>. Similarly, define YAML files for other modules as well.</li> </ol> <pre><code>hf_hub_repo: yomitoku-text-detector-dbnet-open-beta\n</code></pre> <ol> <li>Storing the Path to a YAML File in the Config</li> </ol> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    # path_cfg\u306b\u8a2d\u5b9a\u3057\u305fymal\u306e\u30d1\u30b9\u3092\u8a18\u8ff0\u3059\u308b\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"path_cfg\": \"text_detector.yaml\"\n            }\n        }\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"}]}